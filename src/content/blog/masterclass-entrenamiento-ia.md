---
title: 'Masterclass: Entrenamiento y Fine-Tuning de Modelos IA'
code: "TRAINING"
description: 'Entender la diferencia entre Pre-training, Fine-tuning y RAG. Gu√≠a paso a paso para crear tu propio dataset y entrenar un modelo a medida.'
pubDate: 'Dec 03 2025'
heroImage: '../../assets/blog-placeholder-1.jpg'
---

"Quiero entrenar mi propia IA".

Es la frase m√°s com√∫n y malinterpretada de la industria. La mayor√≠a de la gente no quiere *entrenar* (pre-training), quiere *ajustar* (fine-tuning) o simplemente *conectar* datos (RAG).

En esta masterclass, vamos a abrir el cap√≥ de los LLMs para entender c√≥mo se cocinan y c√≥mo puedes cocinar el tuyo.

---

## üç∞ Las 3 Capas del "Entrenamiento"

Imagina que un LLM es un empleado nuevo.

1.  **Pre-Training (La Universidad):**
    *   **Qu√© es:** Ense√±ar al modelo a *hablar* y entender el mundo. Lee todo internet (Wikipedia, GitHub, Reddit).
    *   **Costo:** Millones de d√≥lares. Miles de GPUs. Meses.
    *   **Qui√©n lo hace:** Google, OpenAI, Meta, Mistral.
    *   **¬øDebes hacerlo t√∫?** **NO**. A menos que tengas el presupuesto de un pa√≠s peque√±o.

2.  **Fine-Tuning (La Especializaci√≥n):**
    *   **Qu√© es:** Tomar un modelo ya entrenado (ej. Llama 3) y ense√±arle una *tarea espec√≠fica* o un *estilo* de respuesta.
    *   **Costo:** Desde $5 USD hasta unos miles.
    *   **Qui√©n lo hace:** Empresas que necesitan un tono de marca espec√≠fico, formatos JSON complejos o respuestas m√©dicas muy t√©cnicas.
    *   **¬øDebes hacerlo t√∫?** Tal vez. Veremos cu√°ndo.

3.  **RAG (Retrieval Augmented Generation - El Manual):**
    *   **Qu√© es:** Darle al modelo acceso a tus documentos PDF/Excel en tiempo real.
    *   **Costo:** Centavos.
    *   **¬øDebes hacerlo t√∫?** **S√ç**. El 99% de los casos de "quiero que la IA sepa sobre mi empresa" se resuelven con RAG, no con entrenamiento.

---

## üéØ ¬øCu√°ndo hacer Fine-Tuning?

El error #1 es creer que el Fine-Tuning es para inyectar *conocimiento*.
**El Fine-Tuning es para inyectar COMPORTAMIENTO.**

*   **‚ùå Mal uso:** "Quiero fine-tunear GPT-4 con los manuales de mi lavadora para que sepa c√≥mo arreglarla."
    *   *Por qu√© falla:* El modelo alucinar√°. Olvidar√° detalles. Es mejor usar RAG.
*   **‚úÖ Buen uso:** "Quiero que el modelo responda siempre en formato JSON, con tono sarc√°stico y usando jerga legal argentina."
    *   *Por qu√© funciona:* Est√°s ense√±ando *forma*, no *fondo*.

---

## üõ†Ô∏è El Proceso de Fine-Tuning (Paso a Paso)

Si decidiste que necesitas Fine-Tuning, este es el camino.

### 1. El Dataset (El Oro)
El modelo ser√° tan bueno como tus datos. Necesitas ejemplos de `Input` -> `Output Ideal`.
El formato est√°ndar es **JSONL** (JSON Lines).

```json
{"messages": [{"role": "system", "content": "Eres un asistente m√©dico."}, {"role": "user", "content": "Me duele la cabeza."}, {"role": "assistant", "content": "DIAGN√ìSTICO: Cefalea tensional. RECOMENDACI√ìN: Paracetamol 500mg."}]}
{"messages": [{"role": "system", "content": "Eres un asistente m√©dico."}, {"role": "user", "content": "Tengo fiebre alta."}, {"role": "assistant", "content": "DIAGN√ìSTICO: Posible infecci√≥n viral. RECOMENDACI√ìN: Reposo y acudir a guardia."}]}
```

**Regla de Oro:** Calidad > Cantidad. 50 ejemplos perfectos son mejores que 5000 mediocres.

### 2. Elegir el Modelo Base
*   **Cerrados (API):** GPT-4o-mini, GPT-3.5-turbo. F√°ciles de usar, pagas por token. Tus datos van a OpenAI.
*   **Abiertos (Open Source):** Llama 3, Mistral, Gemma. Son tuyos. Privacidad total. Requieren GPU.

### 3. El Entrenamiento (The Bake)
Aqu√≠ ajustamos los "pesos" del modelo.
*   **Epochs:** Cu√°ntas veces el modelo ve tus datos. (Usualmente 3-5). Si te pasas, el modelo "memoriza" y pierde flexibilidad (Overfitting).
*   **Learning Rate:** Qu√© tan r√°pido aprende. Muy alto y se rompe; muy bajo y no aprende nada.

### 4. Validaci√≥n
No conf√≠es ciegamente. Separa un 20% de tus datos para "Test". Si el modelo acierta en el entrenamiento pero falla en el test, hiciste Overfitting.

---

## üß™ Herramientas Recomendadas (2025)

### Nivel F√°cil: OpenAI Dashboard
Subes tu `.jsonl`, pagas unos d√≥lares y en 20 minutos tienes tu modelo `ft:gpt-4o-...` listo para usar en la API.

### Nivel Intermedio: Unsloth / Axolotl
Librer√≠as optimizadas para entrenar modelos Open Source (Llama 3) en tu propia m√°quina o en Colab.
*   **Unsloth:** Hace que el fine-tuning sea 2x m√°s r√°pido y use 60% menos memoria. Magia negra matem√°tica.

### Nivel Pro: LoRA / QLoRA
T√©cnicas para entrenar modelos gigantes en GPUs peque√±as. En lugar de re-entrenar todo el cerebro, entrenas una "capa fina" (adapter) que se pone encima.
*   Permite correr un modelo de 70B par√°metros en una GPU de consumidor.

---

## üöÄ Resumen

1.  Si quieres que sepa datos nuevos -> **Usa RAG**.
2.  Si quieres que hable, razone o formatee de una forma muy espec√≠fica -> **Haz Fine-Tuning**.
3.  Empieza peque√±o: 50 ejemplos manuales de alta calidad.
4.  No entrenes desde cero (Pre-training) a menos que seas Google.

El poder ya no est√° en qui√©n tiene el modelo m√°s grande, sino en qui√©n tiene los mejores datos para especializarlo.
